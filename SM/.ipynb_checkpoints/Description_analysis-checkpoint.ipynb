{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91c22f57",
   "metadata": {},
   "source": [
    "# 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "008e2e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fcc4ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "\n",
    "d_netflix = pd.read_csv(\"../Netflix_dataset/titles.csv\")\n",
    "d_hbo = pd.read_csv(\"../HBO_dataset/titles.csv\")\n",
    "d_apple = pd.read_csv(\"../AppleTV_dataset/titles.csv\")\n",
    "d_disney = pd.read_csv(\"../Disney_dataset/titles.csv\")\n",
    "d_paramount = pd.read_csv(\"../Paramount_dataset/titles.csv\")\n",
    "d_amazon = pd.read_csv(\"../Amazon_dataset/titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "19fe84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주석 해제하여 데이터프레임 확인\n",
    "\n",
    "# d_netflix\n",
    "# d_hbo\n",
    "# d_apple\n",
    "# d_disney\n",
    "# d_paramount\n",
    "# d_amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b9c3df9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('d_netflix', 'd_hbo'), ('d_netflix', 'd_apple'), ('d_netflix', 'd_disney'), ('d_netflix', 'd_paramount'), ('d_netflix', 'd_amazon'), ('d_hbo', 'd_apple'), ('d_hbo', 'd_disney'), ('d_hbo', 'd_paramount'), ('d_hbo', 'd_amazon'), ('d_apple', 'd_disney'), ('d_apple', 'd_paramount'), ('d_apple', 'd_amazon'), ('d_disney', 'd_paramount'), ('d_disney', 'd_amazon'), ('d_paramount', 'd_amazon')]\n",
      "15\n",
      "index: 1, pf: ('d_netflix', 'd_hbo')\n",
      "index: 2, pf: ('d_netflix', 'd_apple')\n",
      "index: 3, pf: ('d_netflix', 'd_disney')\n",
      "index: 4, pf: ('d_netflix', 'd_paramount')\n",
      "index: 5, pf: ('d_netflix', 'd_amazon')\n",
      "index: 6, pf: ('d_hbo', 'd_apple')\n",
      "index: 7, pf: ('d_hbo', 'd_disney')\n",
      "index: 8, pf: ('d_hbo', 'd_paramount')\n",
      "index: 9, pf: ('d_hbo', 'd_amazon')\n",
      "index: 10, pf: ('d_apple', 'd_disney')\n",
      "index: 11, pf: ('d_apple', 'd_paramount')\n",
      "index: 12, pf: ('d_apple', 'd_amazon')\n",
      "index: 13, pf: ('d_disney', 'd_paramount')\n",
      "index: 14, pf: ('d_disney', 'd_amazon')\n",
      "index: 15, pf: ('d_paramount', 'd_amazon')\n",
      "merged_df_dict {'merged_df_1': (9, 43), 'merged_df_2': (0, 1), 'merged_df_3': (5, 8), 'merged_df_4': (74, 44), 'merged_df_5': (147, 131), 'merged_df_6': (0, 2), 'merged_df_7': (4, 11), 'merged_df_8': (16, 27), 'merged_df_9': (31, 74), 'merged_df_10': (0, 0), 'merged_df_11': (1, 3), 'merged_df_12': (0, 3), 'merged_df_13': (4, 15), 'merged_df_14': (8, 47), 'merged_df_15': (1608, 108)}\n",
      "merged_df_dict: merged_df_1, true num: 9, false num: 43\n",
      "merged_df_dict: merged_df_2, true num: 0, false num: 1\n",
      "merged_df_dict: merged_df_3, true num: 5, false num: 8\n",
      "merged_df_dict: merged_df_4, true num: 74, false num: 44\n",
      "merged_df_dict: merged_df_5, true num: 147, false num: 131\n",
      "merged_df_dict: merged_df_6, true num: 0, false num: 2\n",
      "merged_df_dict: merged_df_7, true num: 4, false num: 11\n",
      "merged_df_dict: merged_df_8, true num: 16, false num: 27\n",
      "merged_df_dict: merged_df_9, true num: 31, false num: 74\n",
      "merged_df_dict: merged_df_10, true num: 0, false num: 0\n",
      "merged_df_dict: merged_df_11, true num: 1, false num: 3\n",
      "merged_df_dict: merged_df_12, true num: 0, false num: 3\n",
      "merged_df_dict: merged_df_13, true num: 4, false num: 15\n",
      "merged_df_dict: merged_df_14, true num: 8, false num: 47\n",
      "merged_df_dict: merged_df_15, true num: 1608, false num: 108\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations # 조합\n",
    "\n",
    "platforms_list = [\"d_netflix\", \"d_hbo\", \"d_apple\", \"d_disney\", \"d_paramount\", \"d_amazon\"]\n",
    "platforms_dict = {\"d_netflix\" : d_netflix, \n",
    "                        \"d_hbo\" : d_hbo, \n",
    "                        \"d_apple\" : d_apple, \n",
    "                        \"d_disney\" : d_disney, \n",
    "                        \"d_paramount\" : d_paramount, \n",
    "                        \"d_amazon\" : d_amazon}\n",
    "\n",
    "combination_platforms = list(combinations(platforms_list, 2))\n",
    "\n",
    "print(combination_platforms)\n",
    "print(len(combination_platforms))\n",
    "\n",
    "merged_df_dict = {}\n",
    "\n",
    "for index, pf in enumerate(combination_platforms): # pf: platform 2개가 들어있는 튜플\n",
    "    merged_df_name = f\"merged_df_{index+1}\"\n",
    "    print(f\"index: {index+1}, pf: {pf}\")\n",
    "    merged_df = pd.merge(platforms_dict[pf[0]], platforms_dict[pf[1]], on=\"title\")\n",
    "    \n",
    "    df_is_same = merged_df['description_x'] == merged_df['description_y']\n",
    "    \n",
    "    \n",
    "    if True not in df_is_same.value_counts() and False not in df_is_same.value_counts():\n",
    "        merged_df_dict[merged_df_name] = (0, 0)\n",
    "    \n",
    "    elif True not in df_is_same.value_counts():\n",
    "        merged_df_dict[merged_df_name] = (0, df_is_same.value_counts()[False])\n",
    "\n",
    "        # \n",
    "    elif False not in df_is_same.value_counts():\n",
    "        merged_df_dict[merged_df_name] = (df_is_same.value_counts()[True], 0)\n",
    "\n",
    "    else:\n",
    "        merged_df_dict[merged_df_name] = (df_is_same.value_counts()[True], df_is_same.value_counts()[False])\n",
    "\n",
    "# print(\"merged_df_dict\", merged_df_dict)\n",
    "\n",
    "for key, value in merged_df_dict.items():\n",
    "    print(f\"merged_df_dict: {key}, true num: {value[0]}, false num: {value[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "450ed1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>title</th>\n",
       "      <th>type_x</th>\n",
       "      <th>description_x</th>\n",
       "      <th>release_year_x</th>\n",
       "      <th>age_certification_x</th>\n",
       "      <th>runtime_x</th>\n",
       "      <th>genres_x</th>\n",
       "      <th>production_countries_x</th>\n",
       "      <th>seasons_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_certification_y</th>\n",
       "      <th>runtime_y</th>\n",
       "      <th>genres_y</th>\n",
       "      <th>production_countries_y</th>\n",
       "      <th>seasons_y</th>\n",
       "      <th>imdb_id_y</th>\n",
       "      <th>imdb_score_y</th>\n",
       "      <th>imdb_votes_y</th>\n",
       "      <th>tmdb_popularity_y</th>\n",
       "      <th>tmdb_score_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tm132273</td>\n",
       "      <td>Home</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>When Earth is taken over by the overly-confide...</td>\n",
       "      <td>2015</td>\n",
       "      <td>PG</td>\n",
       "      <td>94</td>\n",
       "      <td>['fantasy', 'animation', 'comedy', 'family', '...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>TV-PG</td>\n",
       "      <td>34</td>\n",
       "      <td>['documentation']</td>\n",
       "      <td>['US']</td>\n",
       "      <td>2.0</td>\n",
       "      <td>tt8068900</td>\n",
       "      <td>7.5</td>\n",
       "      <td>853.0</td>\n",
       "      <td>8.093</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_x title type_x                                      description_x  \\\n",
       "0  tm132273  Home  MOVIE  When Earth is taken over by the overly-confide...   \n",
       "\n",
       "   release_year_x age_certification_x  runtime_x  \\\n",
       "0            2015                  PG         94   \n",
       "\n",
       "                                            genres_x production_countries_x  \\\n",
       "0  ['fantasy', 'animation', 'comedy', 'family', '...                 ['US']   \n",
       "\n",
       "   seasons_x  ... age_certification_y  runtime_y           genres_y  \\\n",
       "0        NaN  ...               TV-PG         34  ['documentation']   \n",
       "\n",
       "   production_countries_y  seasons_y  imdb_id_y imdb_score_y imdb_votes_y  \\\n",
       "0                  ['US']        2.0  tt8068900          7.5        853.0   \n",
       "\n",
       "   tmdb_popularity_y tmdb_score_y  \n",
       "0              8.093          7.7  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 제목이 같은 것만 추출\n",
    "merged_df = pd.merge(d_netflix, d_apple, on=\"title\")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "707a8e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>title</th>\n",
       "      <th>type_x</th>\n",
       "      <th>description_x</th>\n",
       "      <th>release_year_x</th>\n",
       "      <th>age_certification_x</th>\n",
       "      <th>runtime_x</th>\n",
       "      <th>genres_x</th>\n",
       "      <th>production_countries_x</th>\n",
       "      <th>seasons_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_certification_y</th>\n",
       "      <th>runtime_y</th>\n",
       "      <th>genres_y</th>\n",
       "      <th>production_countries_y</th>\n",
       "      <th>seasons_y</th>\n",
       "      <th>imdb_id_y</th>\n",
       "      <th>imdb_score_y</th>\n",
       "      <th>imdb_votes_y</th>\n",
       "      <th>tmdb_popularity_y</th>\n",
       "      <th>tmdb_score_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_x, title, type_x, description_x, release_year_x, age_certification_x, runtime_x, genres_x, production_countries_x, seasons_x, imdb_id_x, imdb_score_x, imdb_votes_x, tmdb_popularity_x, tmdb_score_x, id_y, type_y, description_y, release_year_y, age_certification_y, runtime_y, genres_y, production_countries_y, seasons_y, imdb_id_y, imdb_score_y, imdb_votes_y, tmdb_popularity_y, tmdb_score_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 29 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# title과 description이 모두 같은 row\n",
    "df_same_discription = merged_df[merged_df['description_x'] == merged_df['description_y']]\n",
    "df_same_discription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a0324dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Nextflix와 HBO 데이터셋 비교 ------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: True",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m df_is_same \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription_x\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription_y\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------ Nextflix와 HBO 데이터셋 비교 ------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle과 description이 모두 같은 행의 개수: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mdf_is_same\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle은 같지만 description이 다른 행의 개수: \u001b[39m\u001b[38;5;124m\"\u001b[39m, df_is_same\u001b[38;5;241m.\u001b[39mvalue_counts()[\u001b[38;5;28;01mFalse\u001b[39;00m])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: True"
     ]
    }
   ],
   "source": [
    "df_is_same = merged_df['description_x'] == merged_df['description_y']\n",
    "print(\"------ Nextflix와 HBO 데이터셋 비교 ------\\n\")\n",
    "print(\"title과 description이 모두 같은 행의 개수: \", df_is_same.value_counts()[True])\n",
    "print(\"title은 같지만 description이 다른 행의 개수: \", df_is_same.value_counts()[False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb12d34",
   "metadata": {},
   "source": [
    "-> decription이 다르므로, 각 플랫폼의 특성을 반영한 description이라 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5202b1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
